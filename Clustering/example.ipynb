{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright InfinityQ Tech 2024\n",
    "# Author: Brian Mao brian@infinityq.tech\n",
    "# Date: Nov 29, 2024\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from clustering_utils import *\n",
    "from titanq import Model, Vtype, Target, S3Storage\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from statistics import median, variance, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your API Key Here\n",
    "# Obtain your API key by contacting --> support@infinityq.tech\n",
    "# Example: TITANQ_DEV_API_KEY = \"00000000-0000-0000-0000-000000000000\"\n",
    "TITANQ_DEV_API_KEY = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#Specify Total Number of Coordinates + Desired Number of Clusters to Generate\n",
    "#------------------------------------------------------------------------------\n",
    "n_coords = 3000              #Total number of points to cluster (Options: 8, 500, 2000, 3000)\n",
    "n_clusters = 3               #Number of clusters to extract from the data set\n",
    "\n",
    "try:\n",
    "    f = open('instances/input_' + str(n_coords) + '.json')\n",
    "    data = json.load(f)[\"found\"]\n",
    "    coords = []\n",
    "    for coord in data:\n",
    "        coords.append([coord['Longitude'],coord['Latitude']])\n",
    "\n",
    "    plt.title(\"Coordinate Points to Cluster\")\n",
    "    plt.scatter([item[0] for item in coords],[item[1] for item in coords])\n",
    "\n",
    "except:\n",
    "    print(\"ERROR. Input file size does not exist. Must specify n_coords = 8, 500, 2000, or 3000.\")\n",
    "\n",
    "#For plotting generated clusters\n",
    "color_map = {0:\"blue\", 1:\"red\", 2:\"orange\", 3:\"green\", 4:\"black\", 5:\"pink\", 6:\"brown\", 7:\"teal\", 8:\"grey\", 9:\"purple\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify scaling factor for cluster re-balancing (Setting this value to 0.0 deactivates the feature)\n",
    "lambda_scaling_factor = 0.0\n",
    "\n",
    "dist_matrix = gen_dist_matrix(coords)\n",
    "weight_matrix, bias_vector = gen_Jh_cluster(dist_mat=dist_matrix, coords=coords, n_clusters=n_clusters, lambda_scaling_factor=lambda_scaling_factor, k_avg=n_coords/n_clusters, B=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TitanQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(api_key=TITANQ_DEV_API_KEY)\n",
    "model.add_variable_vector('x', n_clusters*n_coords, Vtype.BINARY)\n",
    "model.set_objective_matrices(weight_matrix, bias_vector, Target.MINIMIZE)\n",
    "\n",
    "#Constraint mask for set partioning constraint\n",
    "constraint_mask = np.zeros((n_coords, n_clusters*n_coords))\n",
    "offset = 0\n",
    "for row in range(n_coords):\n",
    "    for col in range(n_clusters):\n",
    "        constraint_mask[row, offset + col] = 1\n",
    "    offset += n_clusters\n",
    "model.add_set_partitioning_constraints_matrix(constraint_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "#Hyperparameters\n",
    "#----------------\n",
    "try:\n",
    "    #Retrieve pre-tuned hyperparameters on existing combinations for the number of clusters and number of coordinates\n",
    "    T_min, T_max, coupling_mult, num_chains, num_engines, timeout = load_hyperparameters(n_coords, n_clusters, lambda_scaling_factor)\n",
    "except:\n",
    "    #Otherwise, use a manually specified set of hyperparameters \n",
    "    T_min = 0.01\n",
    "    T_max = 100 \n",
    "    coupling_mult = 0.1\n",
    "    num_chains = 128\n",
    "    num_engines = 1\n",
    "    timeout = 10\n",
    "\n",
    "betas = 1/(np.linspace(T_min, T_max, num_chains, dtype=np.float32))\n",
    "\n",
    "response = model.optimize(beta=betas, coupling_mult=coupling_mult, timeout_in_secs=timeout, num_chains=num_chains, num_engines=num_engines)\n",
    "activations = np.nonzero(np.reshape(response.x, (-1, n_clusters)))[1]\n",
    "\n",
    "#Store for performance metric calculations\n",
    "titanQ_clusters_dict = {}\n",
    "for i in range(len(activations)):\n",
    "    if activations[i] in titanQ_clusters_dict:\n",
    "        titanQ_clusters_dict[activations[i]].append((coords[i][0], coords[i][1]))\n",
    "    else:\n",
    "        titanQ_clusters_dict[activations[i]] = [(coords[i][0], coords[i][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "titanQ_colors = []\n",
    "for val in activations:\n",
    "    titanQ_colors.append(color_map[val])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"TitanQ Clustering\")\n",
    "plt.scatter([item[0] for item in coords],[item[1] for item in coords], c=titanQ_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = gp.Model(\"Clustering\")\n",
    "\n",
    "#Decision variables\n",
    "x = {}  # x[i, k] = 1 if data point i belongs to cluster k\n",
    "\n",
    "for i in range(n_coords):\n",
    "    for k in range(n_clusters):\n",
    "        x[(i, k)] = model.addVar(vtype=GRB.BINARY, name=f\"x_{i}_{k}\")\n",
    "\n",
    "obj_func = gp.quicksum(dist_matrix[(i,j)] * x[(i,k)] * x[(j,k)]\n",
    "                        for i in range(n_coords) \n",
    "                        for j in range(i+1,n_coords)\n",
    "                        for k in range(n_clusters)\n",
    "                        if (i, k) in x\n",
    "                        if (j, k) in x)   \n",
    "\n",
    "model.setObjective(obj_func, GRB.MINIMIZE)\n",
    "\n",
    "#Constraints\n",
    "for i in range(n_coords):\n",
    "    model.addConstr(\n",
    "            gp.quicksum(x[(i, k)] for k in range(n_clusters)\n",
    "                        if (i, k) in x) == 1,\n",
    "            name=f\"set_partitioning_{i}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solve the model\n",
    "model.optimize()\n",
    "\n",
    "#Print results\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimal solution found.\")      \n",
    "else:\n",
    "    print(\"No optimal solution found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "gurobi_colors = []\n",
    "gurobi_clusters_dict = {}\n",
    "\n",
    "for (i,k) in x:\n",
    "    if x[(i, k)].x > 0.5: #The value of 0.5 is the LP tolerance\n",
    "        gurobi_colors.append(color_map[k])\n",
    "\n",
    "        #Store for performance metric calculations\n",
    "        if k in gurobi_clusters_dict:\n",
    "            gurobi_clusters_dict[k].append((coords[i][0], coords[i][1]))\n",
    "        else:\n",
    "            gurobi_clusters_dict[k] = [(coords[i][0], coords[i][1])]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Gurobi Clustering\")\n",
    "plt.scatter([item[0] for item in coords],[item[1] for item in coords], c=gurobi_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_test = KMeans(n_clusters=n_clusters).fit(coords)\n",
    "\n",
    "#Store for performance metric calculations\n",
    "kmeans_clusters = {}\n",
    "for i in range(len(kmeans_test.labels_)):\n",
    "    if kmeans_test.labels_[i] in kmeans_clusters:\n",
    "        kmeans_clusters[kmeans_test.labels_[i]].append((coords[i][0], coords[i][1]))\n",
    "    else:\n",
    "        kmeans_clusters[kmeans_test.labels_[i]] = [(coords[i][0], coords[i][1])]\n",
    "\n",
    "#Plotting\n",
    "kmeans_colors = []\n",
    "for val in kmeans_test.labels_:\n",
    "    kmeans_colors.append(color_map[val])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.scatter([item[0] for item in coords],[item[1] for item in coords], c=kmeans_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "#Intracluster Performance Metric Calculations\n",
    "#----------------------------------------------\n",
    "titanQ_intracluster_distances = intracluster_distance_calculation(titanQ_clusters_dict)\n",
    "gurobi_intracluster_distances = intracluster_distance_calculation(gurobi_clusters_dict)\n",
    "kmeans_intracluster_distances = intracluster_distance_calculation(kmeans_clusters)\n",
    "\n",
    "#----------------------------------------------\n",
    "#Intercluster Performance Metric Calculations\n",
    "#----------------------------------------------\n",
    "titanQ_intercluster_distances = intercluster_distance_calculation(titanQ_clusters_dict)\n",
    "gurobi_intercluster_distances = intercluster_distance_calculation(gurobi_clusters_dict)\n",
    "kmeans_intercluster_distances = intercluster_distance_calculation(kmeans_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------\n",
    "#Median Calculations\n",
    "#--------------------\n",
    "titanQ_intracluster_median = median(titanQ_intracluster_distances)\n",
    "titanQ_intercluster_median = median(titanQ_intercluster_distances)\n",
    "\n",
    "gurobi_intracluster_median = median(gurobi_intracluster_distances)\n",
    "gurobi_intercluster_median = median(gurobi_intercluster_distances)\n",
    "\n",
    "kmeans_intracluster_median = median(kmeans_intracluster_distances)\n",
    "kmeans_intercluster_median = median(kmeans_intercluster_distances)\n",
    "\n",
    "print(\"TitanQ Intracluster Median:\", titanQ_intracluster_median)\n",
    "print(\"TitanQ Intercluster Median:\", titanQ_intercluster_median)\n",
    "print()\n",
    "\n",
    "print(\"Gurobi Intracluster Median:\", gurobi_intracluster_median)\n",
    "print(\"Gurobi Intercluster Median:\", gurobi_intercluster_median)\n",
    "print()\n",
    "\n",
    "print(\"K-Means Intracluster Median:\", kmeans_intracluster_median)\n",
    "print(\"K-Means Intercluster Median:\", kmeans_intercluster_median)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algorithms_repo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
